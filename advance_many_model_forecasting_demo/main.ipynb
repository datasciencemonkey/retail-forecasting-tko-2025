{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0f54af6-8217-4404-afcb-abc5c9b90447",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Parallel demand forecasting at scale using Ray Tune and Ray Data\n",
    "\n",
    "Batch training and tuning are common tasks in machine learning use-cases. They require training simple models, on data batches, typcially corresponding to different locations, products, etc. Batch training can take less time to process all the data at once, but only if those batches can run in parallel!\n",
    "\n",
    "This notebook showcases how to conduct batch forecasting with NeuralProphet. NeuralProphet is a popular open-source library developed by Facebook and designed for automatic forecasting of univariate time series data. \n",
    "<br></br>\n",
    "<div style=\"text-align: center; line-height: 5; padding-top: 20px;  padding-bottom: 20px;\">\n",
    "  <img src=\"https://docs.ray.io/en/master/_images/batch-training.svg\" alt='Push compute' height=\"300\" width=\"400\">\n",
    "</div>\n",
    "\n",
    "For the data, we will use the M5 walmart dataset.This popular tabular dataset contains historical sales of products for different locations and regions in USA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6f0e53d-e64f-4c9b-bd6c-4bf8c34594b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## This notebook has been tested with ML DBR 16.1 with the below cluster config\n",
    "**Head node** : 28GB 4 Cores <br>\n",
    "**Worker nodes** : 64GB 16 Cores  <br>\n",
    "**max workers** : 3  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be647153-2f42-42a1-b071-8c72368d8875",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install neuralprophet ray[default,tune]==2.41.0 #update to latest version for better support to logging\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7e4e2f2-e2ea-44eb-9029-e1ed66f27571",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Specify catalog Dependencies\n",
    "CATALOG = 'mlops_pj'\n",
    "SCHEMA = 'many_model_forecasting_example'\n",
    "VOLUME = 'walmart'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe1bc24e-8edd-461d-aaec-ff40acffa805",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check if UC assets exists and create them if they do not\n",
    "# spark.sql(f\"CREATE CATALOG IF NOT EXISTS {CATALOG}\")\n",
    "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {SCHEMA}\")\n",
    "spark.sql(f\"USE SCHEMA {SCHEMA}\")\n",
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS {CATALOG}.{SCHEMA}.{VOLUME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea87e6ab-81a7-4e53-aa37-e9e556165fa6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ed29296-1dd4-4590-8387-254d0b9ef18d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "import traceback\n",
    "import math\n",
    "import timeit\n",
    "import torch\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "import pandas as pd\n",
    "import neuralprophet\n",
    "from neuralprophet import NeuralProphet, set_log_level\n",
    "\n",
    "\n",
    "# importing hyperopt and ray\n",
    "from hyperopt import hp\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from ray.tune.stopper import TimeoutStopper\n",
    "from ray.tune.search.concurrency_limiter import ConcurrencyLimiter\n",
    "from ray.runtime_env import RuntimeEnv\n",
    "\n",
    "from hyperopt.pyll import scope\n",
    "from itertools import product\n",
    "from ray.util.multiprocessing import Pool\n",
    "\n",
    "import multiprocessing\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "print(num_cpus)\n",
    "\n",
    "import logging\n",
    "\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import Window\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time, os\n",
    "from ast import literal_eval\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4adeed54-8bd3-4631-bdb1-12090dc478a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Get The cluster information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fed952f-7d2e-4bff-bf73-9a2b60325b9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "ctx = dbutils.notebook.entry_point.getDbutils().notebook().getContext()\n",
    "host_name = ctx.tags().get(\"browserHostName\").get()\n",
    "host_token = ctx.apiToken().get()\n",
    "cluster_id = ctx.tags().get(\"clusterId\").get()\n",
    "\n",
    "response = requests.get(\n",
    "    f'https://{host_name}/api/2.1/clusters/get?cluster_id={cluster_id}',\n",
    "    headers={'Authorization': f'Bearer {host_token}'}\n",
    "  ).json()\n",
    "\n",
    "if \"autoscale\" in response:\n",
    "  min_node = response['autoscale'][\"min_workers\"]\n",
    "  max_node = response['autoscale'][\"max_workers\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97425613-2df2-4e91-81aa-62df0510c847",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Start Ray Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25071795-cc69-45e3-ac02-1d725f943729",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ray\n",
    "import numpy as np \n",
    "from mlflow.utils.databricks_utils import get_databricks_env_vars\n",
    "from ray.util.spark import setup_ray_cluster, shutdown_ray_cluster, MAX_NUM_WORKER_NODES\n",
    "\n",
    "\n",
    "# Cluster cleanup\n",
    "restart = True\n",
    "if restart is True:\n",
    "  try:\n",
    "    shutdown_ray_cluster()\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "  try:\n",
    "    ray.shutdown()\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "# Set configs based on your cluster size\n",
    "num_cpu_cores_per_worker = 15 # total cpu to use in each worker node (total_cores - 1 to leave one core for spark)\n",
    "num_cpus_head_node = 2 # Cores to use in driver node (total_cores - 1)\n",
    "\n",
    "# Set databricks credentials as env vars\n",
    "mlflow_dbrx_creds = get_databricks_env_vars(\"databricks\")\n",
    "os.environ[\"DATABRICKS_HOST\"] = mlflow_dbrx_creds['DATABRICKS_HOST']\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = mlflow_dbrx_creds['DATABRICKS_TOKEN']\n",
    "\n",
    "ray_conf = setup_ray_cluster(\n",
    "  min_worker_nodes=min_node,\n",
    "  max_worker_nodes=max_node,\n",
    "  num_cpus_head_node= num_cpus_head_node,\n",
    "  num_cpus_per_node=num_cpu_cores_per_worker,\n",
    "  num_gpus_head_node=0,\n",
    "  num_gpus_worker_node=0\n",
    ")\n",
    "os.environ['RAY_ADDRESS'] = ray_conf[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bceb40f-05be-495a-899d-bcbdc9ffa390",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Reading walmart data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "670ca2a4-d66c-4c22-920f-ce5df1d0d5b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sdf_walmart = spark.read.table('final_cleaned_filtered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77bc579c-8a57-4653-91b8-ebd51c7fd9eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create Random time-series per model for the Demo.\n",
    "make sure num_items and items_per_model are divisible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5008af4-fa90-42f4-ba94-ec873de76b1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Experiment setup - make sure num_items and items_per_model are divisible\n",
    "num_items = 600  # Max number of item time series to load, full dataset has 30490 which is overkill\n",
    "items_per_model = 100  # Number of item time series per model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0442ed55-de85-405e-8789-9704c4e84b4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "window_spec = Window.orderBy('state_id', 'store_id', 'cat_id', 'dept_id', 'item_id')\n",
    "sdf_walmart_with_model_num = sdf_walmart.withColumn(\"item_num\", F.dense_rank().over(window_spec))  # A unique item number based on the window\n",
    "sdf_walmart_with_model_num = sdf_walmart_with_model_num.filter(sdf_walmart_with_model_num.item_num <= num_items)\n",
    "sdf_walmart_with_model_num = sdf_walmart_with_model_num.withColumn(\"model_num\", F.ceil(F.col(\"item_num\") / items_per_model))\n",
    "sdf_walmart_with_model_num = sdf_walmart_with_model_num.withColumn('y', F.col('sell_price')*F.col('sale_quantity'))\n",
    "sdf_walmart_with_model_num.cache()\n",
    "print(sdf_walmart.count())\n",
    "sdf_walmart_with_model_num.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "144134b2-0da3-449b-bc10-1d5258757345",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## There are multiple ways to convert data from the lakehouse to Ray Data , refer to the [documentation](https://docs.databricks.com/en/machine-learning/ray/connect-spark-ray.html) for more details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ed8e6ef-0cb0-47a5-aeb2-9c7d290ff68c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert spark Dataframe to Ray \n",
    "sdf_ray  = ray.data.from_spark(sdf_walmart_with_model_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81eaec72-129a-43f4-a22b-b34791bd0c3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Many model Forecasting with Ray Tune and Ray Data\n",
    "Ray Tune is a powerful library for hyperparameter tuning, designed to simplify the development of distributed applications. It allows you to efficiently sample hyperparameters and get optimized results on your objective function. Ray Tune provides a variety of state-of-the-art hyperparameter tuning algorithms for optimizing model performance. \n",
    "\n",
    "To use Ray Tune for hyperparameter tuning, you can follow these steps:\n",
    "- Define your training function and objective function.\n",
    "- Specify the hyperparameters and their search space.\n",
    "- Define the pyspark udf function which runs ray tune for each Hierarchial model for the chosen search algorithm and scheduler.\n",
    "- Run the pyspark job and get the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92fe1b62-29c5-4674-abe8-479f726e733a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 1 : Define the training and objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe9f497d-68e4-4dcc-a883-5f4df2d4f2f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def ray_trial(config, df,cpu_resources_per_trial):\n",
    "  \"\"\"\n",
    "  Single ray trial of parameter config \n",
    "  This runs a NeuralProphet model based on the given config and then loads  \n",
    "  \"\"\"\n",
    "\n",
    "  torch.set_num_threads(int(cpu_resources_per_trial)) # Pass the correct cpu to use to improve multi-threading\n",
    "  test_cutoff = df['ds'].max() - pd.Timedelta(days=7) # Take 7 day test cut-ogg\n",
    "  df_train = df[df['ds'] < test_cutoff]\n",
    "  df_test = df\n",
    "  trainer_config = {}\n",
    "\n",
    "  config['n_changepoints'] = 10\n",
    "  config['n_lags'] = 3\n",
    "  config['drop_missing'] = True \n",
    "  config['impute_rolling'] = 1000\n",
    "  config['batch_size'] = 128\n",
    "  config['epochs'] = 10\n",
    "\n",
    "  # Define the Model (it can be any model in our case we use NeuralProphet)\n",
    "  model = NeuralProphet(\n",
    "      accelerator='auto',\n",
    "      trainer_config=trainer_config,\n",
    "      **config\n",
    "  )\n",
    "  start = timeit.default_timer()\n",
    "  # Train model\n",
    "  progress = model.fit(\n",
    "      df=df_train,\n",
    "      checkpointing =True,\n",
    "      freq=\"D\",\n",
    "      metrics=['RMSE'],\n",
    "      progress='bar'\n",
    "    )\n",
    "  total_time = timeit.default_timer()-start\n",
    "  if np.isnan(progress['RMSE'][0]):\n",
    "    progress.fillna(1000, inplace = True)\n",
    "\n",
    "  d_p = progress.loc[progress['RMSE'] == progress['RMSE'].min()].to_dict(orient='records')\n",
    "\n",
    "  print(\"Loss :\",d_p[0]['Loss'])\n",
    "  # Validate the model and get the RMSE Score\n",
    "  forecast_week = model.predict(df[df['ds'] >= (df['ds'].max() - pd.Timedelta(days=360))])\n",
    "  forecast_week = forecast_week[forecast_week['ds'] >= test_cutoff]\n",
    "  forecast_week.y.fillna(0, inplace=True)\n",
    "  forecast_week.yhat1.fillna(0, inplace=True)\n",
    "  test_rmse = mean_squared_error(forecast_week.yhat1.tolist(), forecast_week.y.tolist(), squared=False)\n",
    "  if np.isnan(test_rmse):\n",
    "    test_rmse = 1000\n",
    "  print(\"test_rmse:\",test_rmse)\n",
    "  #Push the final metric to track\n",
    "  ray.train.report({\"RMSE\":test_rmse,\n",
    "              \"Loss\" :d_p[0]['Loss']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05d3ee0d-8432-4926-96e5-c5524cde13e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 2 : Define the search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "212f781f-a89a-4c1c-ad6b-9066b2b65dcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "space_str = \"\"\"\n",
    "{\n",
    "  \"learning_rate\": tune.uniform(0.001, 0.1),\n",
    "  \"n_changepoints\": 10,\n",
    "  \"n_lags\": 3, \n",
    "  'drop_missing': True,\n",
    "  'impute_rolling': 1000,\n",
    "  'newer_samples_weight': tune.uniform(1, 7),\n",
    "  'batch_size': 128,\n",
    "  \"ar_layers\": tune.choice([[64,64,64],[128,128,128],[256,256,256]]),\n",
    "  'epochs': 10\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0beb04b0-c6a6-44bb-b7dd-262d32cf8bb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 3 : Define the Ray Map Groups udf function which runs ray tune for each Hierarchial model for the chosen search algorithm and scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "270ed3c2-447c-42d0-b8fd-3db3bc632f24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Optional, Any\n",
    "\n",
    "from ray import tune,train\n",
    "from ray.tune.search import ConcurrencyLimiter\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.air.integrations.mlflow import MLflowLoggerCallback\n",
    "\n",
    "\n",
    "def udf_parallel_hpt_tune(df,experiment_id,\n",
    "                          parent_id =None,\n",
    "                          cpu_resources_per_trial = 2,\n",
    "                          gpu_resources_per_trial = 0):\n",
    "  \"\"\"\n",
    "  Single ray trial of parameter config \n",
    "  This runs a NeuralProphet model based on the given config and then loads  \n",
    "  \"\"\"\n",
    "  def define_by_run_func(trial) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Define-by-run function to create the search space.\n",
    "    For more information, see https://optuna.readthedocs.io/en/stable\\\n",
    "    /tutorial/10_key_features/002_configurations.html\n",
    "    \"\"\"\n",
    "    trial.suggest_int(\"n_estimators\", 10, 200, log=True)\n",
    "    trial.suggest_float(\"newer_samples_weight\", 1, 7)\n",
    "    trial.suggest_categorical(\"ar_layers\", [[64,64,64],[128,128,128],[256,256,256]])\n",
    "\n",
    "  start = timeit.default_timer()\n",
    "  model_num = df[\"model_num\"][0]\n",
    "  df['date_time'] = pd.to_datetime(df['date_time'], format='%Y-%m-%d')\n",
    "  df = df.sort_values(by='date_time', ascending=True)\n",
    "  df = df.rename(columns={'date_time': 'ds', 'item_num': 'ID'})\n",
    "  df = df[['ID', 'ds', 'y']]\n",
    "  space = eval(space_str)\n",
    "\n",
    "  tune_resources = {\"CPU\": cpu_resources_per_trial} if \\\n",
    "                     gpu_resources_per_trial == 0 else \\\n",
    "                      {\"CPU\": cpu_resources_per_trial,\\\n",
    "                                     \"GPU\": gpu_resources_per_trial}\n",
    "\n",
    "  # Define Optuna search algo\n",
    "  searcher = OptunaSearch(space=space, metric=\"RMSE\", mode=\"min\")\n",
    "\n",
    "  # Tune with callback\n",
    "  tuner = tune.Tuner(\n",
    "      ray.tune.with_resources(ray.tune.with_parameters(\n",
    "          ray_trial, df=df,cpu_resources_per_trial = cpu_resources_per_trial),tune.PlacementGroupFactory([tune_resources])),\n",
    "      tune_config=tune.TuneConfig(\n",
    "          search_alg=searcher,\n",
    "          max_concurrent_trials=max_concurrent_trials,\n",
    "          num_samples=max_concurrent_trials * num_batches,\n",
    "          reuse_actors = True, # Highly recommended for short training jobs (NOT RECOMMENDED FOR GPU AND LONG TRAINING JOBS)\n",
    "          )\n",
    "  )\n",
    "  multinode_results = tuner.fit()\n",
    "  best_trial = multinode_results.get_best_result(metric=\"RMSE\", mode=\"min\", scope='last')\n",
    "  with mlflow.start_run(\n",
    "    run_name=f\"model_{str(model_num)}\",\n",
    "    experiment_id = experiment_id,\n",
    "    tags={\"mlflow.parentRunId\": parent_run.info.run_id},\n",
    "    description=\"run inside ray Map Batches\",\n",
    ") as child_run:\n",
    "    for key ,value in best_trial.config.items():\n",
    "      mlflow.log_param( key = key,\n",
    "                        value = str(value))\n",
    "    mlflow.log_metric(key = 'rmse', value = best_trial.metrics['RMSE'])\n",
    "    mlflow.log_metric(key = 'Loss', value = best_trial.metrics['Loss'])\n",
    "    # mlflow.pyfunc.log_model(best_trial.last_result['checkpoint'], \"model\")\n",
    "\n",
    "  best_rmse = best_trial.metrics['RMSE']\n",
    "\n",
    "  return pd.DataFrame([{\n",
    "  'model_num': model_num,\n",
    "  'model_HPT_time': str(timeit.default_timer()-start), \n",
    "  'num_datapoints': df['y'].count(),\n",
    "  'RMSE': best_rmse,\n",
    "  'space': str(best_trial.config)\n",
    "  }])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b52e639a-4bec-4218-961b-0a36b325aad6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 4 : Run the Map_groups wrapped in MLFLOW and get the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "344a6323-1505-478e-8b42-c12ad92ecfd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "max_concurrent_trials = 3\n",
    "num_batches = 3  # num trials = max_concurrent_trials * num_batches\n",
    "num_models = sdf_walmart_with_model_num.select(F.max('model_num')).collect()[0][0]\n",
    "print(f\"num models : {num_models}\")\n",
    "total_concurrent_trials = num_models*max_concurrent_trials\n",
    "print(f\"Total concurrent Trials: {total_concurrent_trials}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "394138ef-8f3a-4129-8636-936fceaa1001",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "\n",
    "# Grab experiment and model name\n",
    "experiment_name = \"/Users/puneet.jain@databricks.com/ray_test\"\n",
    "\n",
    "if not  mlflow.get_experiment_by_name(experiment_name):\n",
    "  mlflow.set_experiment(experiment_name)\n",
    "  experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "else:\n",
    "  experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "with mlflow.start_run(run_name ='ray_tune_native_mlflow_callback', experiment_id=experiment_id) as parent_run:\n",
    "  result_df = sdf_ray.groupby('model_num').map_groups(udf_parallel_hpt_tune ,\n",
    "                                                    concurrency = num_models,\n",
    "                                                    fn_kwargs = {'parent_id' : parent_run,\n",
    "                                                                 'experiment_id' : experiment_id,\n",
    "                                                                 'cpu_resources_per_trial' : 2,\n",
    "                                                                 'gpu_resources_per_trial' : 0},\n",
    "                                                     batch_format = 'pandas').to_pandas()\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c67be35-c668-4149-ba24-8a4419e134f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Here we dynamically specify the resources to be used based on the cluster choosen betweem CPU and GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3f92745-d08f-4a65-a30f-dfb5dae16b5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## #To Update\n",
    "We see for each trial the cluster utilizes on 25% of the computation\n",
    "<br></br>\n",
    "<div style=\"text-align: center; line-height: 5; padding-top: 20px;  padding-bottom: 20px;\">\n",
    "  <img src=\"https://raw.githubusercontent.com/puneet-jain159/Image_dump/test/ray_25_dash_utilization.png\" alt='Push compute' height=\"1000\" width=\"1600\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8548c3e-32ab-41e5-8ffa-32eda725f61d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Here we see that only 25% percent of the GPU is being utlized to when running the trails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e0c1c83-1a4a-4dfb-a9cf-44ef939c0c06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Improving the cluster utilization\n",
    "\n",
    "Since we are consuming 25% let us increase the number of trails to 4 to utlize the GPU Cluster properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be654e2e-fd94-4577-914f-c058532a0711",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# max_concurrent_trials = 4\n",
    "# num_models = sdf_walmart_with_model_num.select(F.max('model_num')).collect()[0][0]\n",
    "# print(f\"num models : {num_models}\")\n",
    "# total_concurrent_trials = num_models*max_concurrent_trials\n",
    "# print(f\"Total concurrent Trials: {total_concurrent_trials}\")\n",
    "# gpu_resources_per_trial = ray_resources['GPU']/total_concurrent_trials if 'GPU' in ray_resources.keys() else 0\n",
    "# cpu_resources_per_trial = min(int(math.ceil((ray_resources['CPU']/num_models)/max_concurrent_trials)),16)\n",
    "# print(f'gpu_resources_per_trial:{gpu_resources_per_trial}\\ncpu_resources_per_trial:{cpu_resources_per_trial}')\n",
    "# print(f\"***Creating DF to ray tune on {num_models} models with {items_per_model} item time seies per model***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e192e7a-077e-4e5b-923a-8a5fcdf83f84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## #To Update\n",
    "We now see full utlization of the cluster\n",
    "<br></br>\n",
    "<div style=\"text-align: center; line-height: 5; padding-top: 20px;  padding-bottom: 20px;\">\n",
    "  <img src=\"https://raw.githubusercontent.com/puneet-jain159/Image_dump/test/ray_100_dash_utlization_max.png\" alt='Push compute' height=\"1000\" width=\"1600\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc22591e-db76-4da1-8152-994126d86479",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "main",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
