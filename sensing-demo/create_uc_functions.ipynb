{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0184d906-7ada-4439-975a-7dbcab99935a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: databricks-connect in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b70cd9c-b58c-4a51-91b8-7120d5704258/lib/python3.11/site-packages (15.1.0)\nRequirement already satisfied: unitycatalog-ai[databricks] in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b70cd9c-b58c-4a51-91b8-7120d5704258/lib/python3.11/site-packages (0.2.0)\nRequirement already satisfied: asyncio in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b70cd9c-b58c-4a51-91b8-7120d5704258/lib/python3.11/site-packages (from unitycatalog-ai[databricks]) (3.4.3)\nRequirement already satisfied: nest-asyncio in /databricks/python3/lib/python3.11/site-packages (from unitycatalog-ai[databricks]) (1.5.6)\nRequirement already satisfied: pydantic in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b70cd9c-b58c-4a51-91b8-7120d5704258/lib/python3.11/site-packages (from unitycatalog-ai[databricks]) (2.10.6)\nRequirement already satisfied: typing-extensions in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b70cd9c-b58c-4a51-91b8-7120d5704258/lib/python3.11/site-packages (from unitycatalog-ai[databricks]) (4.12.2)\nRequirement already satisfied: unitycatalog-client in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b70cd9c-b58c-4a51-91b8-7120d5704258/lib/python3.11/site-packages (from unitycatalog-ai[databricks]) (0.2.1)\nRequirement already satisfied: databricks-sdk>=0.32.0 in /databricks/python3/lib/python3.11/site-packages (from unitycatalog-ai[databricks]) (0.38.0)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.11/site-packages (from unitycatalog-ai[databricks]) (1.5.3)\nRequirement already satisfied: googleapis-common-protos>=1.56.4 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect) (1.65.0)\nRequirement already satisfied: grpcio-status>=1.56.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect) (1.68.0)\nRequirement already satisfied: grpcio>=1.56.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect) (1.68.0)\nRequirement already satisfied: numpy<2,>=1.15 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect) (1.23.5)\nRequirement already satisfied: packaging>=23.2 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect) (23.2)\nRequirement already satisfied: py4j==0.10.9.7 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect) (0.10.9.7)\nRequirement already satisfied: pyarrow>=4.0.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect) (14.0.1)\nRequirement already satisfied: six in /usr/lib/python3/dist-packages (from databricks-connect) (1.16.0)\nRequirement already satisfied: requests<3,>=2.28.1 in /databricks/python3/lib/python3.11/site-packages (from databricks-sdk>=0.32.0->unitycatalog-ai[databricks]) (2.31.0)\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-sdk>=0.32.0->unitycatalog-ai[databricks]) (2.35.0)\nRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2 in /databricks/python3/lib/python3.11/site-packages (from googleapis-common-protos>=1.56.4->databricks-connect) (5.28.3)\nRequirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.11/site-packages (from pandas->unitycatalog-ai[databricks]) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.11/site-packages (from pandas->unitycatalog-ai[databricks]) (2022.7)\nRequirement already satisfied: annotated-types>=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b70cd9c-b58c-4a51-91b8-7120d5704258/lib/python3.11/site-packages (from pydantic->unitycatalog-ai[databricks]) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b70cd9c-b58c-4a51-91b8-7120d5704258/lib/python3.11/site-packages (from pydantic->unitycatalog-ai[databricks]) (2.27.2)\nRequirement already satisfied: aiohttp-retry>=2.8.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b70cd9c-b58c-4a51-91b8-7120d5704258/lib/python3.11/site-packages (from unitycatalog-client->unitycatalog-ai[databricks]) (2.9.1)\nRequirement already satisfied: aiohttp>=3.8.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b70cd9c-b58c-4a51-91b8-7120d5704258/lib/python3.11/site-packages (from unitycatalog-client->unitycatalog-ai[databricks]) (3.11.12)\nRequirement already satisfied: urllib3>=1.25.3 in /databricks/python3/lib/python3.11/site-packages (from unitycatalog-client->unitycatalog-ai[databricks]) (1.26.16)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b70cd9c-b58c-4a51-91b8-7120d5704258/lib/python3.11/site-packages (from aiohttp>=3.8.4->unitycatalog-client->unitycatalog-ai[databricks]) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b70cd9c-b58c-4a51-91b8-7120d5704258/lib/python3.11/site-packages (from aiohttp>=3.8.4->unitycatalog-client->unitycatalog-ai[databricks]) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b70cd9c-b58c-4a51-91b8-7120d5704258/lib/python3.11/site-packages (from aiohttp>=3.8.4->unitycatalog-client->unitycatalog-ai[databricks]) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b70cd9c-b58c-4a51-91b8-7120d5704258/lib/python3.11/site-packages (from aiohttp>=3.8.4->unitycatalog-client->unitycatalog-ai[databricks]) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b70cd9c-b58c-4a51-91b8-7120d5704258/lib/python3.11/site-packages (from aiohttp>=3.8.4->unitycatalog-client->unitycatalog-ai[databricks]) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b70cd9c-b58c-4a51-91b8-7120d5704258/lib/python3.11/site-packages (from aiohttp>=3.8.4->unitycatalog-client->unitycatalog-ai[databricks]) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b70cd9c-b58c-4a51-91b8-7120d5704258/lib/python3.11/site-packages (from aiohttp>=3.8.4->unitycatalog-client->unitycatalog-ai[databricks]) (1.18.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk>=0.32.0->unitycatalog-ai[databricks]) (5.5.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk>=0.32.0->unitycatalog-ai[databricks]) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk>=0.32.0->unitycatalog-ai[databricks]) (4.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2.28.1->databricks-sdk>=0.32.0->unitycatalog-ai[databricks]) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2.28.1->databricks-sdk>=0.32.0->unitycatalog-ai[databricks]) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2.28.1->databricks-sdk>=0.32.0->unitycatalog-ai[databricks]) (2023.7.22)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk>=0.32.0->unitycatalog-ai[databricks]) (0.4.8)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install unitycatalog-ai[databricks] databricks-connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "972e0004-1d55-47ca-ba8d-09b2daa8d7ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fb22d12-c07b-483c-8fe8-4b58dc96ac0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from unitycatalog.ai.core.databricks import DatabricksFunctionClient\n",
    "\n",
    "client = DatabricksFunctionClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c986907-ef96-418b-b383-535b48e32395",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example catalog and schema names\n",
    "CATALOG = \"mlops_pj\"\n",
    "SCHEMA = \"rag_puneetjain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71e13ba7-58b6-4bf0-bfec-d5f6472c859f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "workspace_client = WorkspaceClient()\n",
    "\n",
    "secret_scope = \"pj\"  # Change me!\n",
    "\n",
    "# Run this if you don't have the API key set to your secrets scope yet\n",
    "\n",
    "# if secret_scope not in [scope.name for scope in workspace_client.secrets.list_scopes()]:\n",
    "#     workspace_client.secrets.create_scope(secret_scope)\n",
    "\n",
    "# my_secret = \"Enter API key\"\n",
    "\n",
    "# workspace_client.secrets.put_secret(scope=secret_scope, key=\"token\", string_value=my_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e032dc6-118c-4aea-8cfd-2b24057a9af2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'ZGFwaTE5YWY4YmUwNDJmZjJiMTRkZjgwN2FlMzUzMjRiNTBi'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " workspace_client.secrets.get_secret(scope=secret_scope, key=\"token\").value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dfc7dd0-2eb0-4592-92c3-dbc2cc5863cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "USE CATALOG mlops_pj;\n",
    "USE SCHEMA rag_puneetjain;\n",
    "CREATE OR REPLACE FUNCTION _genie_query(databricks_host STRING, \n",
    "                  databricks_token STRING,\n",
    "                  space_id STRING,\n",
    "                  question STRING,\n",
    "                  contextual_history STRING)\n",
    "RETURNS STRING\n",
    "LANGUAGE PYTHON\n",
    "COMMENT 'This is a agent that you can converse with to get answers to questions. Try to provide simple questions and provide history if you had prior conversations.'\n",
    "AS\n",
    "$$\n",
    "    import json\n",
    "    import os\n",
    "    import time\n",
    "    from dataclasses import dataclass\n",
    "    from datetime import datetime\n",
    "    from typing import Optional\n",
    "    \n",
    "    import pandas as pd\n",
    "    import requests\n",
    "    \n",
    "    \n",
    "    @dataclass\n",
    "    class GenieResult:\n",
    "        space_id: str\n",
    "        conversation_id: str\n",
    "        question: str\n",
    "        content: Optional[str]\n",
    "        sql_query: Optional[str] = None\n",
    "        sql_query_description: Optional[str] = None\n",
    "        sql_query_result: Optional[pd.DataFrame] = None\n",
    "        error: Optional[str] = None\n",
    "    \n",
    "        def to_json_results(self):\n",
    "            result = {\n",
    "                \"space_id\": self.space_id,\n",
    "                \"conversation_id\": self.conversation_id,\n",
    "                \"question\": self.question,\n",
    "                \"content\": self.content,\n",
    "                \"sql_query\": self.sql_query,\n",
    "                \"sql_query_description\": self.sql_query_description,\n",
    "                \"sql_query_result\": self.sql_query_result.to_dict(\n",
    "                    orient=\"records\") if self.sql_query_result is not None else None,\n",
    "                \"error\": self.error,\n",
    "            }\n",
    "            jsonified_results = json.dumps(result)\n",
    "            return f\"Genie Results are: {jsonified_results}\"\n",
    "    \n",
    "        def to_string_results(self):\n",
    "            results_string = self.sql_query_result.to_dict(orient=\"records\") if self.sql_query_result is not None else None\n",
    "            return (\"Genie Results are: \\n\"\n",
    "                    f\"Space ID: {self.space_id}\\n\"\n",
    "                    f\"Conversation ID: {self.conversation_id}\\n\"\n",
    "                    f\"Question That Was Asked: {self.question}\\n\"\n",
    "                    f\"Content: {self.content}\\n\"\n",
    "                    f\"SQL Query: {self.sql_query}\\n\"\n",
    "                    f\"SQL Query Description: {self.sql_query_description}\\n\"\n",
    "                    f\"SQL Query Result: {results_string}\\n\"\n",
    "                    f\"Error: {self.error}\")\n",
    "    \n",
    "    class GenieClient:\n",
    "    \n",
    "        def __init__(self, *,\n",
    "                     host: Optional[str] = None,\n",
    "                     token: Optional[str] = None,\n",
    "                     api_prefix: str = \"/api/2.0/genie/spaces\"):\n",
    "            self.host = host or os.environ.get(\"DATABRICKS_HOST\")\n",
    "            self.token = token or os.environ.get(\"DATABRICKS_TOKEN\")\n",
    "            assert self.host is not None, \"DATABRICKS_HOST is not set\"\n",
    "            assert self.token is not None, \"DATABRICKS_TOKEN is not set\"\n",
    "            self._workspace_client = requests.Session()\n",
    "            self._workspace_client.headers.update({\"Authorization\": f\"Bearer {self.token}\"})\n",
    "            self._workspace_client.headers.update({\"Content-Type\": \"application/json\"})\n",
    "            self.api_prefix = api_prefix\n",
    "            self.max_retries = 300\n",
    "            self.retry_delay = 1\n",
    "            self.new_line = \"\\r\\n\"\n",
    "    \n",
    "        def _make_url(self, path):\n",
    "            return f\"{self.host.rstrip('/')}/{path.lstrip('/')}\"\n",
    "    \n",
    "        def start(self, space_id: str, start_suffix: str = \"\") -> str:\n",
    "            path = self._make_url(f\"{self.api_prefix}/{space_id}/start-conversation\")\n",
    "            resp = self._workspace_client.post(\n",
    "                url=path,\n",
    "                headers={\"Content-Type\": \"application/json\"},\n",
    "                json={\"content\": \"starting conversation\" if not start_suffix else f\"starting conversation {start_suffix}\"},\n",
    "            )\n",
    "            resp = resp.json()\n",
    "            print(resp)\n",
    "            return resp[\"conversation_id\"]\n",
    "    \n",
    "        def ask(self, space_id: str, conversation_id: str, message: str) -> GenieResult:\n",
    "            path = self._make_url(f\"{self.api_prefix}/{space_id}/conversations/{conversation_id}/messages\")\n",
    "            # TODO: cleanup into a separate state machine\n",
    "            resp_raw = self._workspace_client.post(\n",
    "                url=path,\n",
    "                headers={\"Content-Type\": \"application/json\"},\n",
    "                json={\"content\": message},\n",
    "            )\n",
    "            resp = resp_raw.json()\n",
    "            message_id = resp.get(\"message_id\", resp.get(\"id\"))\n",
    "            if message_id is None:\n",
    "                print(resp, resp_raw.url, resp_raw.status_code, resp_raw.headers)\n",
    "                return GenieResult(content=None, error=\"Failed to get message_id\")\n",
    "    \n",
    "            attempt = 0\n",
    "            query = None\n",
    "            query_description = None\n",
    "            content = None\n",
    "    \n",
    "            while attempt < self.max_retries:\n",
    "                resp_raw = self._workspace_client.get(\n",
    "                    self._make_url(f\"{self.api_prefix}/{space_id}/conversations/{conversation_id}/messages/{message_id}\"),\n",
    "                    headers={\"Content-Type\": \"application/json\"},\n",
    "                )\n",
    "                resp = resp_raw.json()\n",
    "                status = resp[\"status\"]\n",
    "                if status == \"COMPLETED\":\n",
    "                    try:\n",
    "    \n",
    "                        query = resp[\"attachments\"][0][\"query\"][\"query\"]\n",
    "                        query_description = resp[\"attachments\"][0][\"query\"].get(\"description\", None)\n",
    "                        content = resp[\"attachments\"][0].get(\"text\", {}).get(\"content\", None)\n",
    "                    except Exception as e:\n",
    "                        return GenieResult(\n",
    "                            space_id=space_id,\n",
    "                            conversation_id=conversation_id,\n",
    "                            question=message,\n",
    "                            content=resp[\"attachments\"][0].get(\"text\", {}).get(\"content\", None)\n",
    "                        )\n",
    "                    break\n",
    "    \n",
    "                elif status == \"EXECUTING_QUERY\":\n",
    "                    self._workspace_client.get(\n",
    "                        self._make_url(\n",
    "                            f\"{self.api_prefix}/{space_id}/conversations/{conversation_id}/messages/{message_id}/query-result\"),\n",
    "                        headers={\"Content-Type\": \"application/json\"},\n",
    "                    )\n",
    "                elif status in [\"FAILED\", \"CANCELED\"]:\n",
    "                    return GenieResult(\n",
    "                        space_id=space_id,\n",
    "                        conversation_id=conversation_id,\n",
    "                        question=message,\n",
    "                        content=None,\n",
    "                        error=f\"Query failed with status {status}\"\n",
    "                    )\n",
    "                elif status != \"COMPLETED\" and attempt < self.max_retries - 1:\n",
    "                    time.sleep(self.retry_delay)\n",
    "                else:\n",
    "                    return GenieResult(\n",
    "                        space_id=space_id,\n",
    "                        conversation_id=conversation_id,\n",
    "                        question=message,\n",
    "                        content=None,\n",
    "                        error=f\"Query failed or still running after {self.max_retries * self.retry_delay} seconds\"\n",
    "                    )\n",
    "                attempt += 1\n",
    "            resp = self._workspace_client.get(\n",
    "                self._make_url(\n",
    "                    f\"{self.api_prefix}/{space_id}/conversations/{conversation_id}/messages/{message_id}/query-result\"),\n",
    "                headers={\"Content-Type\": \"application/json\"},\n",
    "            )\n",
    "            resp = resp.json()\n",
    "            columns = resp[\"statement_response\"][\"manifest\"][\"schema\"][\"columns\"]\n",
    "            header = [str(col[\"name\"]) for col in columns]\n",
    "            rows = []\n",
    "            output = resp[\"statement_response\"][\"result\"]\n",
    "            if not output:\n",
    "                return GenieResult(\n",
    "                    space_id=space_id,\n",
    "                    conversation_id=conversation_id,\n",
    "                    question=message,\n",
    "                    content=content,\n",
    "                    sql_query=query,\n",
    "                    sql_query_description=query_description,\n",
    "                    sql_query_result=pd.DataFrame([], columns=header),\n",
    "                )\n",
    "            for item in resp[\"statement_response\"][\"result\"][\"data_typed_array\"]:\n",
    "                row = []\n",
    "                for column, value in zip(columns, item[\"values\"]):\n",
    "                    type_name = column[\"type_name\"]\n",
    "                    str_value = value.get(\"str\", None)\n",
    "                    if str_value is None:\n",
    "                        row.append(None)\n",
    "                        continue\n",
    "                    match type_name:\n",
    "                        case \"INT\" | \"LONG\" | \"SHORT\" | \"BYTE\":\n",
    "                            row.append(int(str_value))\n",
    "                        case \"FLOAT\" | \"DOUBLE\" | \"DECIMAL\":\n",
    "                            row.append(float(str_value))\n",
    "                        case \"BOOLEAN\":\n",
    "                            row.append(str_value.lower() == \"true\")\n",
    "                        case \"DATE\":\n",
    "                            row.append(datetime.strptime(str_value, \"%Y-%m-%d\").date())\n",
    "                        case \"TIMESTAMP\":\n",
    "                            row.append(datetime.strptime(str_value, \"%Y-%m-%d %H:%M:%S\"))\n",
    "                        case \"BINARY\":\n",
    "                            row.append(bytes(str_value, \"utf-8\"))\n",
    "                        case _:\n",
    "                            row.append(str_value)\n",
    "                rows.append(row)\n",
    "    \n",
    "            query_result = pd.DataFrame(rows, columns=header)\n",
    "            return GenieResult(\n",
    "                space_id=space_id,\n",
    "                conversation_id=conversation_id,\n",
    "                question=message,\n",
    "                content=content,\n",
    "                sql_query=query,\n",
    "                sql_query_description=query_description,\n",
    "                sql_query_result=query_result,\n",
    "            )\n",
    "    \n",
    "    \n",
    "    assert databricks_host is not None, \"host is not set\"\n",
    "    assert databricks_token is not None, \"token is not set\"\n",
    "    assert space_id is not None, \"space_id is not set\"\n",
    "    assert question is not None, \"question is not set\"\n",
    "    assert contextual_history is not None, \"contextual_history is not set\"\n",
    "    client = GenieClient(host=databricks_host, token=databricks_token)\n",
    "    conversation_id = client.start(space_id)\n",
    "    formatted_message = f\"\"\"Use the contextual history to answer the question. The history may or may not help you. Use it if you find it relevant.\n",
    "    \n",
    "    Contextual History: {contextual_history}\n",
    "    \n",
    "    Question to answer: {question}\n",
    "    \"\"\"\n",
    "    \n",
    "    result = client.ask(space_id, conversation_id, formatted_message)\n",
    "    \n",
    "    return result.to_string_results()\n",
    "\n",
    "$$;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42a66761-71cf-442c-b88e-379e45674344",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION ask_forecasting_questions(question STRING COMMENT \"The question to ask about the updates and adjusted forecast\", contextual_history STRING COMMENT \"provide relevant history to be able to answer this question, assume genie doesn\\'t keep track of history. Use \\'no relevant history\\' if there is nothing relevant to answer the question.\")\n",
    "RETURNS STRING\n",
    "LANGUAGE SQL\n",
    "COMMENT 'This Agent interacts with the Genie space API to provide answers to questions about the lastest updates and adjusted forecasts'  \n",
    "RETURN SELECT _genie_query(\n",
    "  \"https://adb-984752964297111.11.azuredatabricks.net/\",\n",
    "  secret('pj', 'token'),\n",
    "  '01efeaca45c813aba0f6cd461d2c9c9f',\n",
    "  question, -- retrieved from function\n",
    "  contextual_history -- retrieved from function\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbba5532-0026-4d27-b5ea-f72a09452f40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "import json\n",
    "import requests\n",
    "from typing import Any, Dict\n",
    "\n",
    "def score_model(\n",
    "    item_id: int,\n",
    "    location_id: int,\n",
    "    date: str,\n",
    "    current_base_forecast: float,\n",
    "    social_media_index: float,\n",
    "    local_events_count: int,\n",
    "    location_weather: str,\n",
    "    adjusted_demand_forecast: float,\n",
    "    lag1_pos_sales: float,\n",
    "    lag2_pos_sales: float,\n",
    "    secrets : str\n",
    ") -> str:\n",
    "    \"\"\"This is a function which can give updated shipment forecasts for a given item in a given location on a given date.\n",
    "\n",
    "    Args:\n",
    "        item_id (int): The unique identifier for the item.\n",
    "        location_id (int): The unique identifier for the location.\n",
    "        date (str): The forecast date in 'YYYY-MM-DD' format.\n",
    "        current_base_forecast (float): The current base forecast value.\n",
    "        social_media_index (float): The social media index value.\n",
    "        local_events_count (int): The number of local events.\n",
    "        location_weather (str): A string describing the location's weather.\n",
    "        adjusted_demand_forecast (float): The adjusted demand forecast value.\n",
    "        lag1_pos_sales (float): The previous period's positive sales (lag 1).\n",
    "        lag2_pos_sales (float): The sales from two periods ago (lag 2).\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: The JSON response from the scoring endpoint.\n",
    "    \n",
    "    Raises:\n",
    "        Exception: If the remote request returns a status code other than 200.\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import requests\n",
    "    from typing import Any, Dict\n",
    "\n",
    "    url = 'https://adb-984752964297111.11.azuredatabricks.net/serving-endpoints/ship_str_ds_forecast/invocations'\n",
    "    headers = {\n",
    "        'Authorization': f\"Bearer {secrets}\",\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    query_dict = {\n",
    "        \"index\": [0],\n",
    "        \"columns\": [\n",
    "            \"item_id\", \"location_id\", \"date\", \"current_base_forecast\",\n",
    "            \"social_media_index\", \"local_events_count\", \"location_weather\",\n",
    "            \"adjusted_demand_forecast\", \"lag1_pos_sales\", \"lag2_pos_sales\"\n",
    "        ],\n",
    "        \"data\": [[\n",
    "            item_id, location_id, date, current_base_forecast,\n",
    "            social_media_index, local_events_count, location_weather,\n",
    "            adjusted_demand_forecast, lag1_pos_sales, lag2_pos_sales\n",
    "        ]]\n",
    "    }\n",
    "    query_dict = {\"dataframe_split\": query_dict}\n",
    "    data_json = json.dumps(query_dict, allow_nan=True)\n",
    "    response = requests.request(method='POST', headers=headers, url=url, data=data_json)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f'Request failed with status {response.status_code}, {response.text}')\n",
    "    \n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "890e8078-518e-4f50-ab7f-8422794e77a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-80def414-cdf2-40ea-9ef2-25fcd0e4607e/lib/python3.11/site-packages/unitycatalog/ai/core/utils/callable_utils.py:488: UserWarning: In function 'score_model': The following parameters are present in the function signature but not documented in the docstring: secrets\n  check_docstring_signature_consistency(docstring_info.params, params_in_signature, func_name)\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-80def414-cdf2-40ea-9ef2-25fcd0e4607e/lib/python3.11/site-packages/unitycatalog/ai/core/databricks.py:307: UserWarning: The following parameters do not have descriptions: secrets for the function mlops_pj.rag_puneetjain.score_model. Using Unity Catalog functions that do not have parameter descriptions limits the functionality for an LLM to understand how to call your function. To improve tool calling accuracy, provide verbose parameter descriptions that fully explain what the expected usage of the function arguments are.\n  check_function_info(created_function_info)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "FunctionInfo(browse_only=None, catalog_name='mlops_pj', comment='This is a function which can give updated shipment forecasts for a given item in a given location on a given date.', created_at=1739570303590, created_by='puneet.jain@databricks.com', data_type=<ColumnTypeName.STRING: 'STRING'>, external_language='Python', external_name=None, full_data_type='STRING', full_name='mlops_pj.rag_puneetjain.score_model', function_id='ebf6a451-b276-4ca1-9564-f21fd2c09136', input_params=FunctionParameterInfos(parameters=[FunctionParameterInfo(name='item_id', type_text='bigint', type_name=<ColumnTypeName.LONG: 'LONG'>, position=0, comment='The unique identifier for the item.', parameter_default=None, parameter_mode=None, parameter_type=<FunctionParameterType.PARAM: 'PARAM'>, type_interval_type=None, type_json='{\"name\":\"item_id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{\"comment\":\"The unique identifier for the item.\"}}', type_precision=0, type_scale=0), FunctionParameterInfo(name='location_id', type_text='bigint', type_name=<ColumnTypeName.LONG: 'LONG'>, position=1, comment='The unique identifier for the location.', parameter_default=None, parameter_mode=None, parameter_type=<FunctionParameterType.PARAM: 'PARAM'>, type_interval_type=None, type_json='{\"name\":\"location_id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{\"comment\":\"The unique identifier for the location.\"}}', type_precision=0, type_scale=0), FunctionParameterInfo(name='date', type_text='string', type_name=<ColumnTypeName.STRING: 'STRING'>, position=2, comment='The forecast date in \"YYYY-MM-DD\" format.', parameter_default=None, parameter_mode=None, parameter_type=<FunctionParameterType.PARAM: 'PARAM'>, type_interval_type=None, type_json='{\"name\":\"date\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"comment\":\"The forecast date in \\\\\"YYYY-MM-DD\\\\\" format.\"}}', type_precision=0, type_scale=0), FunctionParameterInfo(name='current_base_forecast', type_text='double', type_name=<ColumnTypeName.DOUBLE: 'DOUBLE'>, position=3, comment='The current base forecast value.', parameter_default=None, parameter_mode=None, parameter_type=<FunctionParameterType.PARAM: 'PARAM'>, type_interval_type=None, type_json='{\"name\":\"current_base_forecast\",\"type\":\"double\",\"nullable\":true,\"metadata\":{\"comment\":\"The current base forecast value.\"}}', type_precision=0, type_scale=0), FunctionParameterInfo(name='social_media_index', type_text='double', type_name=<ColumnTypeName.DOUBLE: 'DOUBLE'>, position=4, comment='The social media index value.', parameter_default=None, parameter_mode=None, parameter_type=<FunctionParameterType.PARAM: 'PARAM'>, type_interval_type=None, type_json='{\"name\":\"social_media_index\",\"type\":\"double\",\"nullable\":true,\"metadata\":{\"comment\":\"The social media index value.\"}}', type_precision=0, type_scale=0), FunctionParameterInfo(name='local_events_count', type_text='bigint', type_name=<ColumnTypeName.LONG: 'LONG'>, position=5, comment='The number of local events.', parameter_default=None, parameter_mode=None, parameter_type=<FunctionParameterType.PARAM: 'PARAM'>, type_interval_type=None, type_json='{\"name\":\"local_events_count\",\"type\":\"long\",\"nullable\":true,\"metadata\":{\"comment\":\"The number of local events.\"}}', type_precision=0, type_scale=0), FunctionParameterInfo(name='location_weather', type_text='string', type_name=<ColumnTypeName.STRING: 'STRING'>, position=6, comment='A string describing the location\"s weather.', parameter_default=None, parameter_mode=None, parameter_type=<FunctionParameterType.PARAM: 'PARAM'>, type_interval_type=None, type_json='{\"name\":\"location_weather\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"comment\":\"A string describing the location\\\\\"s weather.\"}}', type_precision=0, type_scale=0), FunctionParameterInfo(name='adjusted_demand_forecast', type_text='double', type_name=<ColumnTypeName.DOUBLE: 'DOUBLE'>, position=7, comment='The adjusted demand forecast value.', parameter_default=None, parameter_mode=None, parameter_type=<FunctionParameterType.PARAM: 'PARAM'>, type_interval_type=None, type_json='{\"name\":\"adjusted_demand_forecast\",\"type\":\"double\",\"nullable\":true,\"metadata\":{\"comment\":\"The adjusted demand forecast value.\"}}', type_precision=0, type_scale=0), FunctionParameterInfo(name='lag1_pos_sales', type_text='double', type_name=<ColumnTypeName.DOUBLE: 'DOUBLE'>, position=8, comment='The previous period\"s positive sales (lag 1).', parameter_default=None, parameter_mode=None, parameter_type=<FunctionParameterType.PARAM: 'PARAM'>, type_interval_type=None, type_json='{\"name\":\"lag1_pos_sales\",\"type\":\"double\",\"nullable\":true,\"metadata\":{\"comment\":\"The previous period\\\\\"s positive sales (lag 1).\"}}', type_precision=0, type_scale=0), FunctionParameterInfo(name='lag2_pos_sales', type_text='double', type_name=<ColumnTypeName.DOUBLE: 'DOUBLE'>, position=9, comment='The sales from two periods ago (lag 2).', parameter_default=None, parameter_mode=None, parameter_type=<FunctionParameterType.PARAM: 'PARAM'>, type_interval_type=None, type_json='{\"name\":\"lag2_pos_sales\",\"type\":\"double\",\"nullable\":true,\"metadata\":{\"comment\":\"The sales from two periods ago (lag 2).\"}}', type_precision=0, type_scale=0), FunctionParameterInfo(name='secrets', type_text='string', type_name=<ColumnTypeName.STRING: 'STRING'>, position=10, comment=None, parameter_default=None, parameter_mode=None, parameter_type=<FunctionParameterType.PARAM: 'PARAM'>, type_interval_type=None, type_json='{\"name\":\"secrets\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}', type_precision=0, type_scale=0)]), is_deterministic=False, is_null_call=None, metastore_id='b86c6879-8c55-4e70-a585-18d16a4fa6e9', name='score_model', owner='puneet.jain@databricks.com', parameter_style=<FunctionInfoParameterStyle.S: 'S'>, properties='{\"sqlConfig.spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.taskWaitTimeInSeconds\":\"1000\",\"sqlConfig.spark.sql.ansi.enabled\":\"true\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.decimal.dataType.enabled\":\"true\",\"sqlConfig.spark.sql.streaming.statefulOperator.stateRebalancing.enabled\":\"false\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.debugLogEnabled\":\"true\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.remoteHttpClient.maxConnections\":\"2048\",\"sqlConfig.spark.sql.legacy.createHiveTableByDefault\":\"false\",\"sqlConfig.spark.sql.streaming.stopTimeout\":\"15s\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.remoteHttpClient.timeoutInSeconds\":\"360\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.enabled\":\"true\",\"sqlConfig.spark.sql.legacy.codingErrorAction\":\"true\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.scaleUpThresholdCurrentQpsIncreaseRatio\":\"0.0\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.scaleUpThresholdTotalQpsIncreaseRatio\":\"0.0\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.useDedicatedHttpClient\":\"true\",\"sqlConfig.spark.sql.readSideCharPadding\":\"true\",\"sqlConfig.spark.sql.variable.substitute\":\"false\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.threadKeepAliveTimeInSeconds\":\"600\",\"sqlConfig.spark.databricks.sql.expression.aiFunctions.repartition\":\"0\",\"sqlConfig.spark.databricks.sql.functions.aiForecast.enabled\":\"false\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.useDynamicTaskQueueExecutor\":\"false\",\"sqlConfig.spark.sql.sources.default\":\"delta\",\"sqlConfig.spark.sql.hive.convertCTAS\":\"true\",\"sqlConfig.spark.databricks.sql.functions.vectorSearch.enabled\":\"true\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.safe.inference.enabled\":\"true\",\"sqlConfig.spark.sql.scripting.enabled\":\"true\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.batch.aiQuery.embedding.request.size\":\"4\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.batch.execution.size\":\"2048\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.clusterSizeBasedGlobalParallelism.scaleFactor\":\"32.0\",\"sqlConfig.spark.databricks.sql.functions.aiGen.endpointName\":\"databricks-meta-llama-3-3-70b-instruct\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.embeddingsEndpointName\":\"databricks-bge-large-en\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.maxPoolSize\":\"2048\",\"sqlConfig.spark.sql.sources.commitProtocolClass\":\"com.databricks.sql.transaction.directory.DirectoryAtomicCommitProtocol\",\"sqlConfig.spark.sql.functions.remoteHttpClient.retryOn400TimeoutError\":\"true\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.adaptiveThreadPool.scaleUpThresholdSuccessRatio\":\"0.95\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.modelEndpointTypeParsing.enabled\":\"true\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.batchInferenceApi.enabled\":\"false\",\"sqlConfig.spark.sql.stableDerivedColumnAlias.enabled\":\"true\",\"sqlConfig.spark.sql.parquet.compression.codec\":\"snappy\",\"sqlConfig.spark.databricks.sql.functions.aiFunctions.model.parameters.enabled\":\"true\",\"sqlConfig.spark.sql.collation.enabled\":\"true\",\"sqlConfig.spark.sql.streaming.stateStore.providerClass\":\"com.databricks.sql.streaming.state.RocksDBStateStoreProvider\"}', return_params=None, routine_body=<FunctionInfoRoutineBody.EXTERNAL: 'EXTERNAL'>, routine_definition='\\n    import json\\n    import requests\\n    from typing import Any, Dict\\n\\n    url = \\'https://adb-984752964297111.11.azuredatabricks.net/serving-endpoints/ship_str_ds_forecast/invocations\\'\\n    headers = {\\n        \\'Authorization\\': f\"Bearer {secrets}\",\\n        \\'Content-Type\\': \\'application/json\\'\\n    }\\n\\n    query_dict = {\\n        \"index\": [0],\\n        \"columns\": [\\n            \"item_id\", \"location_id\", \"date\", \"current_base_forecast\",\\n            \"social_media_index\", \"local_events_count\", \"location_weather\",\\n            \"adjusted_demand_forecast\", \"lag1_pos_sales\", \"lag2_pos_sales\"\\n        ],\\n        \"data\": [[\\n            item_id, location_id, date, current_base_forecast,\\n            social_media_index, local_events_count, location_weather,\\n            adjusted_demand_forecast, lag1_pos_sales, lag2_pos_sales\\n        ]]\\n    }\\n    query_dict = {\"dataframe_split\": query_dict}\\n    data_json = json.dumps(query_dict, allow_nan=True)\\n    response = requests.request(method=\\'POST\\', headers=headers, url=url, data=data_json)\\n\\n    if response.status_code != 200:\\n        raise Exception(f\\'Request failed with status {response.status_code}, {response.text}\\')\\n\\n    return response.json()\\n', routine_dependencies=None, schema_name='rag_puneetjain', security_type=<FunctionInfoSecurityType.DEFINER: 'DEFINER'>, specific_name='score_model', sql_data_access=<FunctionInfoSqlDataAccess.NO_SQL: 'NO_SQL'>, sql_path=None, updated_at=1739570303590, updated_by='puneet.jain@databricks.com')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_python_function(func=score_model, catalog=CATALOG, schema=SCHEMA, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a64cf0a-1e3b-4601-ac8a-efa7ebef44e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION mlops_pj.rag_puneetjain.get_updated_shipment_forecast(\n",
    "  item_id INTEGER COMMENT \"The unique identifier for the item.\",\n",
    "  location_id INTEGER COMMENT \"The unique identifier for the location\",\n",
    "  date  STRING COMMENT \"The forecast date in 'YYYY-MM-DD' format\",\n",
    "  current_base_forecast FLOAT COMMENT \"The current base forecast value\",\n",
    "  social_media_index FLOAT COMMENT \"The social media index value.\",\n",
    "  local_events_count INTEGER COMMENT \"The number of local events.\",\n",
    "  location_weather STRING COMMENT \"A string describing the location's weather.\",\n",
    "  adjusted_demand_forecast float COMMENT \"The adjusted demand forecast value.\",\n",
    "  lag1_pos_sales FLOAT COMMENT \"The previous period's positive sales (lag 1)\",\n",
    "  lag2_pos_sales FLOAT COMMENT \"The sales from two periods ago (lag 2)\")\n",
    "RETURNS STRING\n",
    "LANGUAGE SQL\n",
    "COMMENT 'This is a function which can give updated shipment forecasts for a given item in a given location on a given date'  \n",
    "RETURN SELECT mlops_pj.rag_puneetjain.score_model(\n",
    "   item_id,\n",
    "   location_id,\n",
    "   date,\n",
    "   current_base_forecast,\n",
    "   social_media_index,\n",
    "   local_events_count,\n",
    "   location_weather,\n",
    "   adjusted_demand_forecast,\n",
    "   lag1_pos_sales,\n",
    "   lag2_pos_sales,\n",
    "   secret('pj', 'token')\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98498ff4-6365-4c1a-bb5d-9ea0bf57a5c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'predictions': [100.1899873703072]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model(\n",
    "   item_id = 1,\n",
    "    location_id =1,\n",
    "    date= \"2024-10-12\",\n",
    "    current_base_forecast=101,\n",
    "    social_media_index =105,\n",
    "    local_events_count =1,\n",
    "    location_weather= \"cloudy\",\n",
    "    adjusted_demand_forecast= 103,\n",
    "    lag1_pos_sales= 100,\n",
    "    lag2_pos_sales= 97\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2efdf22b-02a4-4088-b825-84f21bbad8fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1641673815784074,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Create UC functions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}